################################################################################
# Copyright (c) 2021 ContinualAI.                                              #
# Copyrights licensed under the MIT License.                                   #
# See the accompanying LICENSE file for terms.                                 #
#                                                                              #
# Date: 12-10-2020                                                             #
# Author(s): Eli Verwimp                                                       #
# E-mail: contact@continualai.org                                              #
# Website: avalanche.continualai.org                                           #
################################################################################

# Always maintain half of the minibatch drawed from current mini-batch.

"""
This example shows how to train models provided by pytorchcv with the rehearsal
strategy.
"""

from os.path import expanduser

import argparse
import torch
from torch.nn import CrossEntropyLoss
from torchvision import transforms
from torchvision.datasets import CIFAR10
from torchvision.transforms import ToTensor
import torch.optim.lr_scheduler
from avalanche.benchmarks.classic import SplitCIFAR10

from avalanche.benchmarks import nc_benchmark
from avalanche.models import pytorchcv_wrapper
from avalanche.training.supervised import Naive
from avalanche.training import Replay
from avalanche.training.plugins import EarlyStoppingPlugin
from avalanche.training.plugins import ReplayPlugin
from avalanche.evaluation.metrics import (
    forgetting_metrics,
    accuracy_metrics,
    loss_metrics,
)
from avalanche.logging import InteractiveLogger
from avalanche.training.plugins import EvaluationPlugin


def main(args):
    # Model getter: specify dataset and depth of the network.
    model = pytorchcv_wrapper.resnet("cifar10", depth=20, pretrained=False)

    # Or get a more specific model. E.g. wide resnet, with depth 40 and growth
    # factor 8 for Cifar 10.
    # model = pytorchcv_wrapper.get_model("wrn40_8_cifar10", pretrained=False)

    # --- CONFIG
    device = torch.device(
        f"cuda:{args.cuda}" if torch.cuda.is_available() and args.cuda >= 0 else "cpu"
    )

    # --- TRANSFORMATIONS
    transform = transforms.Compose(
        [
            ToTensor(),
            transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)),
        ]
    )

    # --- BENCHMARK CREATION
    cifar_train = CIFAR10(
        root=expanduser("~") + "/.avalanche/data/cifar10/",
        train=True,
        download=True,
        transform=transform,
    )
    cifar_test = CIFAR10(
        root=expanduser("~") + "/.avalanche/data/cifar10/",
        train=False,
        download=True,
        transform=transform,
    )

    # Is this benchmark model..? like resnet?
    # I think its a dataloader
    benchmark = SplitCIFAR10(
        n_experiences=6,
        first_exp_with_half_classes=True,
        fixed_class_order=[9-i for i in range(10)]
    )

    # benchmark = nc_benchmark( 
    #     cifar_train,
    #     cifar_test,
    #     5,
    #     task_labels=False,
    #     seed=1234,
    #     fixed_class_order=[i for i in range(10)],
    # )

    # choose some metrics and evaluation method
    interactive_logger = InteractiveLogger()

    eval_plugin = EvaluationPlugin(
        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),
        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),
        forgetting_metrics(experience=True),
        loggers=[interactive_logger],
    )

    # CREATE THE STRATEGY INSTANCE (Naive, with Replay) # Maybe continual learning strategy (including model, optimizer)
    cl_strategy = Naive( # continual? or curriculam? 
        model,
        torch.optim.SGD(model.parameters(), lr=0.01),
        CrossEntropyLoss(),
        train_mb_size=100,
        train_epochs=10,
        eval_mb_size=100,
        device=device,
        plugins=[ReplayPlugin(mem_size=100000,batch_size=100),EarlyStoppingPlugin(patience=1,val_stream_name="train_stream")],
        evaluator=eval_plugin,
    )

    # TRAINING LOOP
    print("Starting experiment...")
    results = []
    cnt=0
    for experience in benchmark.train_stream:
        cnt+=1
        num=0
        for data in experience.dataset:
            num+=1
            if(num%5000==0):
                print(f"cur num of data : {num}")
                print(f"shapes : {data[0].shape},{data[1]},{data[2]}")

        print(f"type(experience): {type(experience)}, num: {cnt}")
        print("Start of experience ", experience.current_experience)
        cl_strategy.train(experience)
        print("Training completed")

        print("Computing accuracy on the whole test set")
        results.append(cl_strategy.eval(benchmark.test_stream))


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--cuda",
        type=int,
        default=0,
        help="Select zero-indexed cuda device. -1 to use CPU.",
    )
    args = parser.parse_args()
    main(args)


# python cifar10_half.py | tee log/halfhalf
# ReplayPlugin(mem_size=100000)
# 0.1690, 0.1548, 0.1516, 0.1745 -> 0.162475

'''
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 50/50 [00:02<00:00, 23.78it/s]
> Eval on experience 0 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.4406
        Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.4345
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0696
-- Starting eval on experience 1 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 26.39it/s]
> Eval on experience 1 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.6750
        Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.0092
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2340
-- Starting eval on experience 2 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 23.01it/s]
> Eval on experience 2 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.9680
        Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.4515
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000
-- Starting eval on experience 3 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 25.24it/s]
> Eval on experience 3 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp003 = 0.8130
        Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.2487
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1350
-- Starting eval on experience 4 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 22.28it/s]
> Eval on experience 4 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp004 = 0.9880
        Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.3651
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000
-- Starting eval on experience 5 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 25.97it/s]
> Eval on experience 5 (Task 0) from test stream ended.
        Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 0.4534
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.9730
-- >> End of eval phase << --
        Loss_Stream/eval_phase/test_stream/Task000 = 2.1700
        Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1690

'''


# ReplayPlugin(mem_size=100000,batch_size=100)
# 0.1839, 0.1633, 0.1524, 0.1496 -> 0.1623

'''
-- Starting eval on experience 0 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 50/50 [00:02<00:00, 19.04it/s]
> Eval on experience 0 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.4268
        Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.4540
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0762
-- Starting eval on experience 1 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 19.16it/s]
> Eval on experience 1 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.4290
        Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.8841
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4940
-- Starting eval on experience 2 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 21.39it/s]
> Eval on experience 2 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.9400
        Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.3098
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0020
-- Starting eval on experience 3 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 18.04it/s]
> Eval on experience 3 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp003 = 0.9420
        Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.3823
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0020
-- Starting eval on experience 4 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 18.84it/s]
> Eval on experience 4 (Task 0) from test stream ended.
        ExperienceForgetting/eval_phase/test_stream/Task000/Exp004 = 0.9870
        Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.4957
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000
-- Starting eval on experience 5 (Task 0) from test stream --
100%|????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????| 10/10 [00:00<00:00, 24.38it/s]
> Eval on experience 5 (Task 0) from test stream ended.
        Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 0.4986
        Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.9600
-- >> End of eval phase << --
        Loss_Stream/eval_phase/test_stream/Task000 = 2.1840
        Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1839
'''